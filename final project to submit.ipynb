{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing relevant packages\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "kdd=pd.read_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\DataMiningProject\\kddcup99_train_.csv\")\n",
    "display(kdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#defining the explanatory variables\n",
    "X=kdd.copy()\n",
    "X.drop(columns=['connection_category'],inplace=True)\n",
    "\n",
    "#defining the explained variable\n",
    "y=kdd['connection_category'].copy()\n",
    "\n",
    "\n",
    "#checking if we've got what we wanted\n",
    "display(y)\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "display(x_train)\n",
    "display(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the optimal parameters for Decision Tree model\n",
    "DecisionTree=DecisionTreeClassifier()\n",
    "parameters={'max_depth':range(1,7),'min_impurity_decrease':[0.1,0.0001,0.001,0.01],'criterion':['gini','entropy'], \n",
    "            'min_samples_split':[2,4,6]}\n",
    "# \n",
    "#[0.0001,0.001,0.01,0.1]\n",
    "grid_DesicionTree=GridSearchCV(estimator=DecisionTree, param_grid=parameters, cv=5,scoring='f1_macro')\n",
    "grid_DesicionTree.fit(x_train,y_train)\n",
    "\n",
    "#printing the parameters that give the optimal Decision Tree\n",
    "print(grid_DesicionTree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Optimal DecisionTree model\n",
    "Dec_tree_model = DecisionTreeClassifier(criterion='entropy', max_depth=6, min_impurity_decrease=0.0001, min_samples_split= 4)\n",
    "Dec_tree_model.fit(x_train, y_train)\n",
    "print(Dec_tree_model)\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = Dec_tree_model.predict(x_test)\n",
    "\n",
    "#creating confusion matrix\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "\n",
    "#calculating f1 score for this model\n",
    "print(\"f1 score of the DecisionTree model is: \",f1_score(expected, predicted, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the optimal parameters for Random Forest model\n",
    "rf=RandomForestClassifier(n_estimators=100)\n",
    "parameters_rf={'max_depth':range(1,7),'min_impurity_decrease':[0.0001,0.001,0.01,0.1],'criterion':['gini','entropy'], \n",
    "            'min_samples_split':[2,4,6]}\n",
    "\n",
    "grid_params_rf=GridSearchCV(estimator=rf, param_grid=parameters_rf, cv=5, scoring='f1_macro')\n",
    "grid_params_rf.fit(x_train,y_train.values.ravel())\n",
    "\n",
    "#printing the parameters that give the optimal Random Forest\n",
    "print(grid_params_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##RandomForest model\n",
    "RandomForest = RandomForestClassifier(criterion='entropy', max_depth=6, min_impurity_decrease=0.0001, \n",
    "                                       min_samples_split=4)\n",
    "\n",
    "    \n",
    "RandomForest.fit(x_train, y_train.values.ravel())\n",
    "y_pred = RandomForest.predict(x_test)\n",
    "\n",
    "#calculating f1 score for this model\n",
    "print(\"f1 score of the RandomForest model is: \", f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the optimal parameters for AdaBoost model\n",
    "DecisionTree=DecisionTreeClassifier()\n",
    "AdaBoost = AdaBoostClassifier(base_estimator=DecisionTree)\n",
    "parameters_AdaBoost={'learning_rate':[0.05, 0.01, 0.1, 0.5, 1],\n",
    "                     'base_estimator__criterion':['gini','entropy'],\n",
    "                     \"base_estimator__splitter\":[\"best\", \"random\"],\"n_estimators\": [ 100, 120, 150,200]}\n",
    "\n",
    "grid_params_Ada=GridSearchCV(estimator=AdaBoost, param_grid=parameters_AdaBoost, cv=5, scoring='f1_macro')\n",
    "grid_params_Ada.fit(x_train,y_train.values.ravel())\n",
    "\n",
    "#printing the parameters that give the optimal Decision Tree\n",
    "print(grid_params_Ada.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##AdaBoost optimal model\n",
    "DecisionTree=DecisionTreeClassifier(criterion='entropy',splitter='best')\n",
    "opt_AdaBoost = AdaBoostClassifier(base_estimator=DecisionTree,\n",
    "                                  learning_rate=0.5, n_estimators=200)\n",
    "opt_AdaBoost.fit(x_train, y_train.values.ravel())\n",
    "y_pred = opt_AdaBoost.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating f1 score for this model\n",
    "print(\"f1 score of the AdaBoost model is: \",f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "####final stage - implying the chosen model on the test data\n",
    "\n",
    "###loading the test data\n",
    "final_test=pd.read_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\DataMiningProject\\kddcup99_test_blind_.csv\")\n",
    "display(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##defining the explenatory variables\n",
    "final_X=final_test.copy()\n",
    "final_X.drop(columns=['ID','connection_category'],inplace=True)\n",
    "\n",
    "display(final_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implying optimal AdaBoost on test data\n",
    "final_y_pred=opt_AdaBoost.predict(final_X)\n",
    "print(final_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##writing the prediction to the csv file\n",
    "test_to_submit = pd.read_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\DataMiningProject\\kddcup99_test_blind_to_upload.csv\")\n",
    "test_to_submit['connection_category'] = final_y_pred\n",
    "display(test_to_submit)\n",
    "test_to_submit.to_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\DataMiningProject\\pred_submittion_file.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
